{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "LqAPw4sGtc5q",
    "outputId": "09547b5d-9ee8-467f-e9d7-a29131c8dce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "lelQaFlxt69Y",
    "outputId": "5b692ab7-359c-4270-a216-10851d20e636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/hw4\n",
      "data.zip       testing_data.txt    training_nolabel.txt\n",
      "hw4-RNN.ipynb  training_label.txt\n"
     ]
    }
   ],
   "source": [
    "# %cd /content/drive/My\\ Drive/hw4\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "rVXjBWBnutd-",
    "outputId": "ae4b96c9-ad83-4714-8b4a-f08dd9759f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8\n",
      "To: /content/drive/My Drive/hw4/data.zip\n",
      "\r",
      "0.00B [00:00, ?B/s]\r",
      "4.72MB [00:00, 43.7MB/s]\r",
      "20.4MB [00:00, 55.7MB/s]\r",
      "34.1MB [00:00, 65.3MB/s]\r",
      "45.1MB [00:00, 96.9MB/s]\n",
      "Archive:  data.zip\n",
      "  inflating: training_label.txt      \n",
      "  inflating: testing_data.txt        \n",
      "  inflating: training_nolabel.txt    \n",
      "data.zip       testing_data.txt    training_nolabel.txt\n",
      "hw4-RNN.ipynb  training_label.txt\n"
     ]
    }
   ],
   "source": [
    "# !gdown --id '1lz0Wtwxsh5YCPdqQ3E3l_nbfJT1N13V8' --output data.zip\n",
    "# !unzip data.zip\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJOePatYtgTy"
   },
   "source": [
    "#### 1. 训练词向量\n",
    "使用train.txt和test.txt训练word2vec，存储到‘w2v.model’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xhVyfsiB16Ih"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from gensim.models import word2vec\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "78aXrVVfvXhy",
    "outputId": "67eeb024-d8de-4690-cf67-90b80cb03c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 +++$+++ are wtf ... awww thanks !\n",
      "\n",
      "1 +++$+++ leavingg to wait for kaysie to arrive myspacin itt for now ilmmthek .!\n",
      "\n",
      "0 +++$+++ i wish i could go and see duffy when she comes to mamaia romania .\n",
      "\n",
      "1 +++$+++ i know eep ! i can ' t wait for one more day ....\n",
      "\n",
      "0 +++$+++ so scared and feeling sick . fuck ! hope someone at hr help ... wish it would be wendita or karen .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('training_label.txt', 'r') as f:\n",
    "    for raw in f.readlines()[:5]:\n",
    "        print(raw)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2R7FodrDw9lj"
   },
   "outputs": [],
   "source": [
    "with open('testing_data.txt', 'r') as f:\n",
    "    for raw in f.readlines()[:5]:\n",
    "        print(raw)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lm8vAG_VzMxN"
   },
   "outputs": [],
   "source": [
    "raws = raw.strip('\\n').split(',')\n",
    "x = ','.join(raws[1:])\n",
    "x = x.split(' ')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SscVlhGuu4HY"
   },
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    x = []\n",
    "    y = []\n",
    "    with open(path, 'r') as f:\n",
    "        for raw in f.readlines():\n",
    "            raws = raw.strip('\\n').split(' ')\n",
    "            y.append(int(raws[0]))\n",
    "            x.append(raws[2:])\n",
    "    f.close()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f-jVitt8x79e"
   },
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    x = []\n",
    "    with open(path, 'r') as f:\n",
    "        for raw in f.readlines()[1:]:\n",
    "            raws = raw.strip('\\n').split(',')\n",
    "            text = ','.join(raws[1:])\n",
    "            x.append(text.split(' '))\n",
    "    f.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWzL3WVz0ik4"
   },
   "outputs": [],
   "source": [
    "def train_word2vec(x):\n",
    "    model = word2vec.Word2Vec(x, size=200, window=5, min_count=5, iter=10, sg=1)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "skWxz0Jj142o",
    "outputId": "a1619274-0eda-41ac-98ca-09ccfa7c540d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading training data……\n",
      "train_x.size: 200000\n",
      "loading testing data……\n",
      "test_x.size: 200000\n",
      "saving model ……\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "print('loading training data ……')\n",
    "train_x, train_y = load_train_data('training_label.txt')\n",
    "print('train_x.size: {}'.format(len(train_x)))\n",
    "\n",
    "print('loading testing data……')\n",
    "test_x = load_test_data('testing_data.txt')\n",
    "print('test_x.size: {}'.format(len(test_x)))\n",
    "\n",
    "word2vec_model = train_word2vec(train_x + test_x)\n",
    "print('saving model ……')\n",
    "word2vec_model.save('w2v.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olvO_BEBDYNp"
   },
   "source": [
    "#### 2. 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ej8ugl_LDbIJ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1107b427851e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w2v.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec' is not defined"
     ]
    }
   ],
   "source": [
    "tmp = word2vec.Word2Vec.load('w2v.model')\n",
    "tmp.vector_size\n",
    "tmp['is']\n",
    "tmp.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sQ8oih7JmQp"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from gensim.models import Word2Vec\n",
    "class Preprocess():\n",
    "    def __init__(self, sentences, seq_len, w2v_path='w2v.model'):\n",
    "        self.seq_len = seq_len\n",
    "        self.idx2word = [] # idx2word[0] = 'he'\n",
    "        self.word2idx = {} # word2idx['he'] = 0\n",
    "        self.embedding_matrix = [] # sentences的embedding矩阵\n",
    "        self.embedding = Word2Vec.load(w2v_path) # 加载预训练好的词向量 embedding['word'] = vector\n",
    "    \n",
    "    def add_embedding(self, word):\n",
    "        # 将<unk>,<pad>加入,随机初始化值即可\n",
    "        vector = torch.randn(1, self.embedding.vector_size)\n",
    "        self.word2idx[word] = len(self.idx2word)\n",
    "        self.idx2word.append(word)\n",
    "        self.embedding_matrix = torch.cat([self.embedding_matrix, vector], 0)\n",
    "\n",
    "    def make_embedding(self):\n",
    "        print('get embedding')\n",
    "        for i, word in enumerate(self.embedding.wv.vocab):\n",
    "            self.word2idx['word'] = len(self.word2idx)\n",
    "            self.idx2word.append(word)\n",
    "            self.embedding_matrix.append(self.embedding[word])\n",
    "        \n",
    "        self.embedding_matrix = torch.tensor(self.embedding_matrix)\n",
    "        self.add_embedding('<PAD>')\n",
    "        self.add_embedding('<UNK>')\n",
    "        return self.embedding_matrix\n",
    "    \n",
    "    def pad_sequence(self, sentence): \n",
    "        if len(sentence) > self.seq_len:\n",
    "            sentence = sentence[:seq_len]\n",
    "        else:\n",
    "            pad_len = self.seq_len - len(sentence)\n",
    "            for _ in range(pad_len):\n",
    "                sentence.append(self.word2idx['<PAD>'])\n",
    "        assert len(sentence) == self.seq_len\n",
    "        return sentence\n",
    "      \n",
    "    def sentence_word2idx(self, sentence):\n",
    "        # 把句子里的词对应到index\n",
    "        sentence_idx = []\n",
    "        for i, word in enumerate(sentence):\n",
    "            if word in self.word2idx.keys():\n",
    "                sentence_idx.append(self.word2idx[word])\n",
    "            else:\n",
    "                sentence_idx.append(self.word2idx['<UNK>'])\n",
    "        sentence_idx = self.pad_sequence(sentence_idx)\n",
    "        return torch.tensor(sentence_idx)\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterDataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.data = x\n",
    "        self.label = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.data[index],self.label[index]\n",
    "        else:\n",
    "            return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4-RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
